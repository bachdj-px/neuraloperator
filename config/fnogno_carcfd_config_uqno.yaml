cfd: &CFD

  arch: 'fnogno'
  sample_max: 5000
  verbose: True

  # Distributed computing
  distributed:
    use_distributed: False
    wireup_info: 'mpi'
    wireup_store: 'tcp'
    model_parallel_size: 2
    seed: 666
    device: 'cuda'

  # Dataset related
  data:
    root: PATH_TO_CFD_DATA
    sdf_query_resolution: 64
    n_train: 500
    n_train_solution: 350
    n_train_residual: 150
    n_calib_residual: 56 # (first 51 from the test data set)
    n_test: 111 # (the last 50 from the test dataset)
    # n_train: 500
    # n_train_solution: 312
    # n_train_residual: 125
    # n_calib_residual: 63
    # n_test: 111
    download: False

  save_dir: SAVE_DIR

  fnogno:
    data_channels: 1
    out_channels: 1
    gno_coord_dim: 3
    gno_coord_embed_dim: 16
    gno_radius: 0.055
    gno_transform_type: 'linear' # linear_kernelonly, linear, nonlinear_kernelonly, nonlinear
    gno_pos_embed_type: "transformer"
    fno_n_layers: 16 # default was 4
    fno_n_modes: [32, 32, 32]
    fno_hidden_channels: 86
    fno_use_channel_mlp: True
    fno_norm: 'group_norm' #'instance_norm'
    fno_ada_in_features: 64
    fno_factorization: 'tucker'
    fno_rank: 0.4
    fno_domain_padding: 0.125
    fno_channel_mlp_expansion: 1.0
    fno_resolution_scaling_factor: 1

  opt:
    alpha: 0.9
    delta: 0.95
    solution:
      n_epochs: 0 # 300
      learning_rate: 1e-3
      training_loss: 'l2' 
      testing_loss: 'l2' 
      weight_decay: 1e-4
      amp_autocast: False

      scheduler_T_max: 500 # For cosine only, typically take n_epochs
      scheduler_patience: 5 # For ReduceLROnPlateau only
      scheduler: 'StepLR' # Or 'CosineAnnealingLR' OR 'ReduceLROnPlateau'
      step_size: 50
      gamma: 0.5
    
    residual:
      n_epochs: 300
      learning_rate: 1e-3
      training_loss: 'l2' 
      testing_loss: 'l2' 
      weight_decay: 1e-4
      amp_autocast: False

      scheduler_T_max: 500 # For cosine only, typically take n_epochs
      scheduler_patience: 5 # For ReduceLROnPlateau only
      scheduler: 'StepLR' # Or 'CosineAnnealingLR' OR 'ReduceLROnPlateau'
      step_size: 50
      gamma: 0.5

  # Weights and biases
  wandb:
    log: False #True
    name: None # If None, config will be used but you can override it here
    group: 'drag' 
    project: ""
    entity: ""
    sweep: False
    log_output: True
    eval_interval: 1
